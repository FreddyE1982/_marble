resource_allocator:
  max_disk_mb: 30720  # maximum MB for disk offload (30 GB)
  compress_offload: true  # store offloaded tensors in float16
  min_gpu_tensor_mb: 0.0  # send all tensors to GPU regardless of size
  ram_offload_threshold: 0.9  # offload tensors to disk when RAM usage exceeds this ratio
  vram_offload_threshold: 0.9  # move tensors off GPU when VRAM usage exceeds this ratio
  disk_usage_threshold: 0.95  # stop offloading when disk usage exceeds this ratio
snapshot:
  compress_level: 2  # gzip compression level (1-9) for Brain.save_snapshot
  tensor_precision: 16  # bit precision for tensors stored in Brain.save_snapshot (8, 16, or 32)
reporter:
  tensorboard:
    enabled: true  # write all reporter updates to TensorBoard
    log_dir: null  # default SummaryWriter location when null
    flush_interval_steps: 5  # flush writer every N reporter updates
autoplugin:
  decision_interval: 1  # steps between plugin selector decisions
decision_controller:
  budget: null  # null -> auto-mode
  warmup_steps: 10
  safety_factor: 1.2
  recalc_interval: 100
  contribution_l1: 0.01  # L1 penalty for contribution regressor
  tau_threshold: 1.0  # minimum seconds between state changes before penalty
  cadence: 1  # walk steps between controller decisions
  dwell_bonus: 0.1  # cost reduction per consecutive active step
  lambda_lr: 0.1  # learning rate for constraint multipliers
  dwell_threshold: 1  # minimum steps before a plugin may change state
  phase_count: 1  # number of discrete phases for gating
  watch_metrics: []  # reporter paths to monitor automatically
  watch_variables: []  # module.variable paths to observe
  policy_mode: policy-gradient  # 'policy-gradient' or 'bayesian'
  auto_cost_profile: false  # profile plugin runtime to infer missing costs
  log_path: null  # optional newline-delimited JSON log written every decision
  moe_routing:
    enabled: false  # enable the MoE router to gate wanderer plugins
    decision_interval: 1  # router refresh interval in steps
    capacity_factor: 1.25  # multiplier controlling number of active experts
    min_active_experts: 1  # lower bound on active experts
    max_active_experts: 4  # upper bound on active experts
    load_balance_alpha: 0.15  # strength of load-balancing penalty
    load_balance_decay: 0.8  # EMA decay for router load tracking
    budget_weight: 0.25  # smoothing factor for latency budget estimates
    cadence_scale: 0.25  # influence of budget pressure on controller cadence
    lambda_scale: 0.15  # influence of budget pressure on constraint multipliers
    feedback_decay: 0.4  # smoothing applied to budget pressure feedback
    budget_target: 1.0  # desired budget pressure (1.0 == on target)
    topk_balance_scale: 0.0  # optional multiplier for load-balance based top-k boosts
  linear_constraints:
    A: []  # constraint matrix; columns follow sorted plugin names
    b: []  # upper bounds paired with rows in A
max_flat_steps: 5  # consecutive zero-delta steps before pruning/connection
auto_scale_targets: false  # scale tiny targets to match output magnitude
auto_max_steps_interval: 10  # recompute wanderer max_steps every N datapairs
reward_shaper:
  window_size: 10  # number of recent steps for OLS
  w1: 1.0  # weight for latency slope
  w2: 1.0  # weight for throughput slope
  w3: 1.0  # weight for cost slope
  w4: 1.0  # weight for throughput-normalized drop
  w5: 1.0  # weight for divergence indicator
  w6: 1.0  # weight for action penalties
  M_div: 0.1  # divergence threshold for throughput drop
