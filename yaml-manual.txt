# YAML Manual

## Neuroplasticity Training Parameters

- aggressive_starting_neuroplasticity (bool, default: false)
  Enables an initial phase where a minimum number of neurons is added at each training step.
- add_min_new_neurons_per_step (int)
  Required when aggressive_starting_neuroplasticity is true. Minimum neurons to grow per step during the aggressive phase.
- aggressive_phase_steps (int)
  Required when aggressive_starting_neuroplasticity is true. Number of steps to keep aggressive growth before reverting to normal behaviour.

- max_flat_steps (int, default: 5)
  Maximum number of consecutive walk steps a neuron can report a ``delta`` of
  ``0.0`` before it is marked for pruning or a new synaptic connection is
  forced via plugin. Must be non-negative.

- auto_scale_targets (bool, default: false)
  When enabled, ``run_training_with_datapairs`` attaches the AutoTargetScaler
  plugin which observes early training steps and rescales targets so their
  magnitude roughly matches model outputs. This stabilizes loss when targets
  are orders of magnitude smaller than predictions.

- auto_max_steps_interval (int, default: 10)
  After every ``n`` datapairs, the Wanderer recomputes the longest path in the
  current Brain and uses that length as ``max_steps`` for subsequent walks.
  Set to ``0`` to disable automatic updates.

## Resource Allocator Settings

 - resource_allocator.max_disk_mb (int, default: 30720)
  Limits total size in MB of tensors offloaded to disk by the resource allocator.
  Must be positive. When exceeded, tensors are cleared instead of offloaded.
- resource_allocator.compress_offload (bool, default: true)
  When true, tensors moved to CPU or disk are converted to ``float16`` to save
  space. They are restored to their original dtype when reloaded.
- resource_allocator.min_gpu_tensor_mb (float, default: 0.0)
  Minimum tensor size in megabytes required before the allocator considers
  moving it to GPU. A value of ``0.0`` sends every tensor to GPU regardless of
  size.
- resource_allocator.ram_offload_threshold (float, default: 0.9)
  RAM usage ratio beyond which rarely accessed tensors are proactively
  offloaded to disk. Value must be between 0 and 1.
- resource_allocator.vram_offload_threshold (float, default: 0.9)
  VRAM usage ratio beyond which tensors are moved off the GPU to CPU or disk.
  Value must be between 0 and 1.
- resource_allocator.disk_usage_threshold (float, default: 0.95)
  Maximum allowed disk usage ratio before tensors are offloaded. Prevents disk
  exhaustion; value must be between 0 and 1.

## AutoPlugin Settings

- autoplugin.decision_interval (int, default: 1)
  Number of walk steps between plugin selection decisions. Plugins retain their
  previous activation state on intermediate steps. Must be at least ``1``.

## Decision Controller Settings

- decision_controller.budget (float, default: 10.0)
  Maximum cumulative cost allowed for plugin actions during a single decision
  step. Actions exceeding the remaining budget are discarded starting with the
  highest cost.
- decision_controller.contribution_l1 (float, default: 0.01)
  L1 penalty strength applied when training the plugin contribution regressor.
  Higher values yield sparser contribution weights.
- decision_controller.tau_threshold (float, default: 1.0)
  Minimum seconds a plugin should wait between state changes. When the actual
  interval \(\tau_t\) falls below this value, a penalty of ``tau_threshold - \tau_t``
  is added to the plugin's cost during action selection.
- decision_controller.cadence (int, default: 1)
  Number of walk steps between successive decisions of the controller. Actions
  are only reconsidered on steps that are multiples of this cadence. Must be at
  least 1.
- decision_controller.dwell_bonus (float, default: 0.1)
  Cost reduction applied for each consecutive step a plugin remains active.
  Larger values encourage persistence by making long-running plugins
  progressively cheaper under the budget constraint.
- decision_controller.watch_metrics (list[str], default: [])
  Reporter item paths (``group[/subgroup]/item``) automatically queried each
  decision step. Numeric values are merged into the ``metrics`` dict supplied
  to :meth:`DecisionController.decide`.
- decision_controller.watch_variables (list[str], default: [])
  Fully qualified ``module.attr`` names of numeric variables to observe. Their
  current values are sampled every decision and merged into the ``metrics``
  dictionary.

## Reward Shaper Settings

- reward_shaper.window_size (int, default: 10)
  Number of recent performance samples kept for computing OLS trends used to
  shape actor-critic rewards. Must be at least 2.
